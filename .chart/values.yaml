## number of exporter instances
##
replicaCount: 1

## restart policy for all containers
##
restartPolicy: Always

image:
  registry: 625240141681.dkr.ecr.eu-west-1.amazonaws.com
  tag: latest
  pullPolicy: IfNotPresent

git:
  sha:
  branch: master

resources: {}
  # requests:
  #   cpu: 100m
  #   memory: 128Mi
  # limits:
  #   cpu: 100m
  #   memory: 128Mi

priorityClassName: ""

nodeSelector: {}

tolerations: {}

podAnnotations: {}

service:
  type: ClusterIP
  httpPort: 9108
  annotations: {}

es:
  ## Address (host and port) of the Elasticsearch node we should connect to.
  ## This could be a local node (localhost:9200, for instance), or the address
  ## of a remote Elasticsearch server. When basic auth is needed,
  ## specify as: <proto>://<user>:<password>@<host>:<port>. e.g., http://admin:pass@localhost:9200.
  ##
  uri: http://elasticsearch-client:9200

  ## If true, query stats for all nodes in the cluster, rather than just the
  ## node we connect to.
  ##
  all: true

  ## If true, query stats for all indices in the cluster.
  ##
  indices: true
  indicesParseStats: "*_newlogs_{dt_layout}"
  indicesDTLayout: "20060102"

  ## If true, query stats for all shards
  ##
  shards: true

  ## Timeout for trying to get stats from Elasticsearch. (ex: 20s)
  ##
  timeout: 60s

  ssl:
    ## If true, a secure connection to ES cluster is used (requires SSL certs below)
    ##
    enabled: false

    ca:

      ## PEM that contains trusted CAs used for setting up secure Elasticsearch connection
      ##
      # pem:

    client:

      ## PEM that contains the client cert to connect to Elasticsearch.
      ##
      # pem:

      ## Private key for client auth when connecting to Elasticsearch
      ##
      # key:

web:
  ## Path under which to expose metrics.
  ##
  path: /metrics

serviceMonitor:
  ## If true, a ServiceMonitor CRD is created for a prometheus operator
  ## https://github.com/coreos/prometheus-operator
  ##
  enabled: true
  scrapeInterval: 60s
  labels:
    prometheus: kube-prometheus

prometheusRules:
  rules:
  - expr: sum(elasticsearch_indices_store_size_bytes_primary) by (index)
    record: elasticsearch:indices_store_size_bytes_primary:sum
  - expr: count(sum(elasticsearch_indices_shared_docs) by (index,shard)) by (index)
    record: elasticsearch:indices_shards:count
  - expr: sum(label_replace(label_replace(label_replace(elasticsearch:indices_store_size_bytes_primary:sum, "company_id", "$1", "index", "(.*)_newlogs_.*"), "alias", "$1", "index", "(.*_newlogs_.*)-.*"), "index_id", "$1", "index", ".*_newlogs_.*-(.*)")) without (index)
    record: elasticsearch:size_bytes_per_shard:relabel
  - expr: sum(label_replace(label_replace(label_replace((count(sum(elasticsearch_indices_shared_docs) by (index,shard)) by (index)), "company_id", "$1", "index", "(.*)_newlogs_.*"), "alias", "$1", "index", "(.*_newlogs_.*)-.*"), "index_id", "$1", "index", ".*_newlogs_.*-(.*)")) without (index)
    record: elasticsearch:indices_shards_count:relabel
  - expr: (elasticsearch:size_bytes_per_shard:relabel / elasticsearch:indices_shards_count:relabel) / 1000000000
    record: elasticsearch:size_gb_per_shard:div

prometheusAlerts:
  alerts:
  - alert: ShardsGigabytesThreshold
    annotations:
      description: "Alias {{ $labels.alias }} of company ID {{ $labels.company_id }} probably need to be spitted <http://localhost:3000/d/X1PqGyeik/split-shards?var-datasource=prod&var-company_id={{ $labels.company_id }}|Grafana Link> (Index id {{ $labels.index_id }})"
    expr: elasticsearch:size_gb_per_shard:div > 7.5 and elasticsearch:indices_shards_count:relabel < 15
    for: 450s
